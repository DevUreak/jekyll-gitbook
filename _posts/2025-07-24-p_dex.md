---
title: "[Project] Fully On-chain DEX"
author: Tao He
date: 2021-08-10
category: Jekyll
layout: post
---

Overview
-------------

Fully On-chain Dex는 매칭 엔진을 Smart Contract로 마이그레이션하여 온체인환경에 적합한 탈중앙화된 오더북을 구동하는것이다.
초기 [Clober Finance V1](https://github.com/clober-dex) 모델에 영감을 받았으며, 자동화된 유동성 분배 알고리즘을 개발하여 기존 AMM에 비해 매칭엔진에서 소모되는 Gas비를 줄여 결과적으로  트레이딩에 사용되는 슬리피지를 줄임과 동시에 사용자에게 다양한 주문 옵션을 제공하려는것이 가장 큰 목표 이다.
<br>
- 프로젝트를 분석및 연구에 대한 내용은 투고한 논문을 통해서 확인가능하다. <br>
        * [원문](https://drive.google.com/file/d/1Lk0NbaKR5synhVLe1AR2zRhfEw-uUvML/view?usp=sharing)<br>
        * [학술지](https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE12039232)
- 모든 섹션에서는 **기여한 부분과 공개가능한** 부분만 설명하고자한다. 

Algorithms
-------------
거래에서의 슬리피지를 줄이기위해서는 기술적인 최적화도 필요하지만 가스비를 포함한 자본의 리턴이 최종적으로 얼마인지를 생각해봐야합니다.
프로젝트에서는 ALD라는 방정식을 사용합니다. 방정식은 유동성과 가격의 상관관계에 대한 해석을 기반으로 실험을 통해 경험적으로 도출되었습니다.
<br><br>
ALD는 3가지 전략적인 배치방식을 제공합니다. 배치방식은 방정식에서 $s$ (유동성 배치 방식을 결정하기 위한 계수 decay) 값을 통해서 결정됩니다. 
양수,음수,0 세가지 유형을 유동성 크기에 따라 서서히 그 모습을 변화시키도록 고안되어 있다.

1. Concentrated Distruibution <br>
![img]({{ site.baseurl }}/assets/ald1.png){: style="width:500px;","display: block; margin: 0;" }

2. Inverted and Concentrated Distribution <br>
![img]({{ site.baseurl }}/assets/ald3.png){: style="width:500px;","display: block; margin: 0;" }

3. Cliff and Equalized, Inverted Distribution <br>
![img]({{ site.baseurl }}/assets/ald2.png){: style="width:500px;","display: block; margin: 0;" }
<br>

모든 데이터는 컨트랙트 개발 환경을 통해 추출하였다. AMM
모델은 유니스왑 공식 레포지토리를 참조하여 컨트랙트를 포크하여 구현하였고, ALD는 방정식을 온체인 컨트랙트로 구현했다. 
이를 통해 추출한 데이터는 Python 의 Matplotlib 을 통해 시각화하였다.
<br>

결과적으로 전략적 배치는 성공적으로 유동성에 따라서 유동적으로 변화하여 상황에 적합하게 동작할수있었다. 
이를 통해 아래와 같이 실제 바이낸스 BTC/USDT 차트의 MarketDepth를 상하반전된 형태로 보면 시장부근에 집중화된 형태의 유동성이 
분포가 되어있는것을 확인할수있다. 
<br>
![img]({{ site.baseurl }}/assets/ald4.png){: style="width:500px;","display: block; margin: 0;height:250px; object-fit: cover; object-position: top; display: block;" }
<p style="font-size: 0.8em; color: #666; margin-top: -10px; margin-left:100px">
  BTC/USDT Market Depth of Binance(2024.08.07)
</p>
<br>

Solidity Optimization
-------------
자본 효율성을 높이기 위해, 기술적으로 개선이 가능한 가스비 최적화 영역에 어셈블리 코드를 도입했다. 최신 Solidity 버전기준으로 함수 시그니처 검증, 리턴 데이터 크기와 타입 안전성, revert 처리 등 다양한 유효성 검증 기능이 내장되어 있지만, 어셈블리를 최소한의 형태로 직접 구현하는 것은 리스크가 높아진다. 
하지만 충분한 시나리오 기반 테스트를 통해 잠재적인 위험을 최소화할 수 있다고 판단하여, 해당 방법을 신중하게 적용하였다.


-------------
```
    function push(Type.Order memory _order) public returns (bytes32 _key) {
        unchecked {
            ...
            _push(_order.owner, _key);
            ...
        }
    }

    function _push(address _owner, bytes32 _key) internal {
        assembly {
            mstore(0x00, caller())
            mstore(0x20, keys.slot)
            let outerSlot := keccak256(0x00, 0x40)
            mstore(0x00, _owner)
            mstore(0x20, outerSlot)
            let innerSlot := keccak256(0x00, 0x40)

            let size := sload(innerSlot)
            mstore(0x00, innerSlot)
            let dataSlot := keccak256(0x00, 0x20)

            sstore(add(dataSlot, size), _key)
            sstore(innerSlot, add(size, 1))
        }
    }
```
위와 같이 이중배열에 저장할때 메모리 주소(0x00,0x20) 재사용하여 가스비를 줄이고 필요한 유효성 검사인(owner, key 값 확인 등)는 상위 호출에서 검사하게 구현하였다.
***가스비는 20% 절감했다.***


Extensible Proxy
-------------
일반적으로 Solidity는 Proxy패턴을 사용하는이유는 이미 배포된 계약을 다른 계약으로 교체하고 이로인한 상황에서 배포 가스비를 절감할수있다.
그러나 Solidity는 24kb로 컨트랙트의 비지니스로직과 기본적으로 생성되는 바이트코드들을 분리함으로 얻는 공간 확보외에 비지니스로직이 비대해지면 
확장성문제를 겪을수밖에없다. 온체인에 오더북을 구현하기위한 매칭엔진과 여러 주문 방식과 스테이킹 같은 서비스를 제공하기위해서는 해당 문제를 해결해야만했다. 
리서치를 통해 EIP-2535를 적용하여 확장성 문제를 해결하였다. 해당 솔루션은 구현복잡성이 올라가지만 이로인해 실행 가스비를 줄일수있는 optimaztion 수치를 크게 높여 가스비를 줄일수있는 
장점이었다. 결과적으로 매칭엔진을 통해서 사용자들이 주문을하는 경우에는 ***10%이상의 가스비*** 가 감소하였다.
<br><br>
최대한 경량화하여 프로젝트에 적용한 방식은 다음 [주소](https://github.com/Coinmeca/lightweight-diamond)를 통해서 확인가능하다. 
<br>



Backend
-------------
### Overview
스마트 컨트랙트 직접 호출로 서비스 이용은 가능하지만, 복잡한 파라미터 계산과 트랜잭션 생성을 사용자가 직접 해야 해 현실적이지 않다.
특히 Uniswap V3는 집중 유동성 도입으로 최적 경로 계산이 매우 복잡해졌고, Auto Router API 같은 백엔드 인프라가 필수가 되었다. 이 없이는 V3의 핵심인 '자본 효율성'을 제대로 활용할 수 없다. 백엔드 기술은 블록체인 서비스를 '제품' 으로 만드는 핵심 요소다.
<br><br>
MVP 단계에서는 아래와같은 아키텍처로 구성이 되었다.
<br>
![img]({{ site.baseurl }}/assets/arc1.png){: style="width:800px;","display: block; margin: 0;" }
<br>
API,Scheduler,OrderManager,Crawler 등 4개의 서비스로 구성되고 서비스간 통신은 GRPC를 선택했다. 나는 백앤드 비지니스 로직 개발과 GraphQL 적용및 서비스 기능 개선에 기여했다.
<br>

각 서비스는 아래와 같은 기능을 수행한다. 
- **API** <br>
```
    registry, _ := registry.Init(config, repositories) // 캐싱및 스토리지
    registry.Bootstrap() // bootstrap components 
    go server.StartInternalServer(registry, *config) // grpc 
    gateway.StartGatewayServer(registry, config, repositories) // graphql
```
registry에서는 TransactionManager 서비스로부터 즉각적인 동기화가 요구되지않는 데이터(ex. TVL)를 캐싱하거나 그외 API 요청에는 DB 조회를 통해서 핸들링한 이후 
데이터를 내려주게된다. 실시간 데이터 스트리밍이 필요한 데이터는 Graphql SSE 기능을 사용한다. 

- **Scheduler** <br>
각각의 태스크는 DB Polling을 통해서 특정 데이터(ex. TVL)를 합산및 연산을 수행한다. 서버 부트스크랩시 지정된 태스크들의 객체를 생성하여 일정한 주기로 반복 작업을 수행하였고 이는 DB에 저장된 크론 표현식으로 서비스의 상태에 걸맞게 커스터마이징이 가능한형태로 구현되었다. 각각의 배치를 관리하는 형태는 아래와 같다. 

``` 
    createdAt:2024. 3. 31. 오후 11:12:18 {    "_id" : ObjectId("66096f4278fdaf67677e133c"),    "batchId" : 3,    "term" : "* * * * * *", // 크론 표현식
    "cate" : "market",    "title" : "TestMarket",    "contractAddress" : "",    "chain" : "Polygon",    "description" : "Description for the third document"},
    
    createdAt:2024. 3. 31. 오후 11:12:18*/{    "_id" : ObjectId("66096f4278fdaf67677e133b"),    "batchId" : 2,    "term" : "*/5 * * * * *",    "cate" : "vault",    "title" : "TestVault",    "contractAddress" : "",    "chain" : "BSC",    "description" : "Description for the second document"},
    ...
```

  서비스간 grpc 통신을 하지않고 독립적인 체제를 유지하면서 데이터를 가공하여 DB에 저장한다. 

- **TransactionManager** <br>
Crawler로 부터 전달받은 Onchain 이벤트 데이터를 각 조건에 맞는 형태로 재가공되어 DB에 저장됨과 동시에 API 서비스에게 전달된다. 

- **Crawler** <br>
EVM기반 주기적으로 Polling 한다. 블록 데이터를 수집한뒤 이후 주소필터링을 통해 지정된 주소의 블록을 TransactionManager 서비스에 Protocol Buffers로 Marshaling 된상태로 전송한다. 


### NoSQL 그리고 OHLC
기존 PostgreSQL에서 NoSQL 젼환의 가장 큰이유는 안정성 보다 속도와 확장성에 좀더 집중하였기 때문이다. 에자일을 지향할수밖에 없던 
당시 개발 속도적인 측면에서 컨트랙트가 완성이안되 이벤트 스키마가 계속 변화하는 시점에서 스키마리스는 큰 메리트로 느껴졌다. 그리고 시계열 데이터 처리 측면에서 버킷팅으로 
저장공간을 절약되고 [OHLC](https://www.mongodb.com/developer/products/mongodb/time-series-candlestick/) 구성하는 캔들 스틱을 구성하는 문서 또한 정리가 잘되어있었다. 
비용이 절반정도 저렴한 MongoDB는 그당시 주머니 사정을 해결해주었다.
<br>
```
type Chart struct {
	Chain string                 `json:"chainId" bson:"chainId"`
	Address string               `json:"address" bson:"address"`
	Time    int64                `json:"time" bson:"time"`
	Open    primitive.Decimal128 `json:"open" bson:"open"`
	High    primitive.Decimal128 `json:"high" bson:"high"`
	Low     primitive.Decimal128 `json:"low" bson:"low"`
	Close   primitive.Decimal128 `json:"close" bson:"close"`
    ...
}
```
차트 데이터를 구성하는 OHLC 레이아웃은 위와 같다. 멀티체인을 위한 Chain와 Pool Pair 주소로 필터링을 하는구조다. 

### GraphQL vs RestAPI
RestAPI는 오버패칭과 언더패칭 문제와 고정된 스키마로 인해 유연성이 부족하다. 그리고 한번의 요청으로 GraphQL은 필요한정보를 패칭 할수있는 반면 
RestAPI는 여러번 호출해야할수도있고 아니면 추가적인 개발을 요구할수있다. 그리고 스트리밍 서비스가 필요한데 WebSocket 구현 방식보다 간단하게 구독 모델을 구현하여 스트리밍 서비스를 
유지할수있는것이 큰 장점이다. 

```
graph/
├── model/
│   ├──model.go                     # Auto-generated
├── resolver/
│   ├── resolver.go                 # request&response API
│   └── subscription.resolvers.go   # 실시간 데이터 스트림 서비스
├── schema/
│   ├── query.graphqls              # API 스키마 
│   ├── subscription.graphqls       # 스키마 
│   └── type/                       # object type
│       ├── order.graphql           # ex. 오더 타입 정의
├── server/
│   ├── server.go                   # GraphQL 서버 설정

```
디렉토리 구조는 [99designs 라이브러리](https://github.com/99designs/gqlgen)에 의해 위와같이 구성하였고, schema에 API요청시 내려줄 객체 타입을 지정해주고 
query 형태를 지정해주면 빌드시 model과 resolver의 abstract가 generate 된다. API 요청에따른 데이터 패칭 핸들링은 resolver에서 진행한다. subscription 접두사붙는 형태는 
프론트에 실시간 데이터 스트림을 제공할 비지니스로직을 작성했다. graphql 서비스는 API 서비스가 부트스트랩될때 server.go 객체를 생성하여 같이 초기화 된다.


### Service flow
TransactionManager 대표적으로 설명한다. 디렉토리 구조는 아래와같이 사용된다. 
<br>
```
TransactionManager/
├── model/
│   ├──model.go                 # Auto-generated
├── controller/
│   ├── controller_farm.go      # 데이터 핸들링
├── conf/
│   ├── config.toml             # env 파일
│   ├── config.go               # env 타입 지정및 env 객체 공유
├── common/
│   ├── common.go               # GraphQL 서버 설정
```
<br>
main.go 부트스트랩시 Grpc Server가 초기화되면서 Controller에 연결된다. Crawler부터 rpc 통해 전송받은 데이터는 아래 Handler 를 통해 매핑 이후 Controller에 전해진다.
<br>
```
func (s *TransactionService) Send(ctx context.Context, req *pb.GeneralRequest) (*pb.GeneralResponse, error) {
	// oneof 요청의 타입을 확인
	switch x := req.Request.(type) {
	case *pb.GeneralRequest_Transaction:
		// Transaction 타입의 요청을 처리
		data := x.Transaction
		// 실제 트랜잭션 데이터 처리 로직을 여기에 추가
		txData := commondatabase.GrpcTxData{
			Id:          data.Data.Id,
			BlockHash:   data.Data.BlockHash,
			BlockNumber: data.Data.BlockNumber,
			Hash:        data.Data.Hash,
			ChainId:     data.Data.ChainId,
			...
		}
		s.controller.ProcessEvent(&txData)
    ...
}
```
<br>
전달된 데이터는 Controller의 processEvent에서 다시 서비스 핸들러에 전달된다. 이후 각 Controller는 이벤트 인덱싱을 통해서 해당 비지니스로직을 수행하고 DB 저장및 필요시 API 서버에 grpc를 통해서 필요한 데이터가 전송된다.
<br>
```
func (c *ContractHandler) processEvent(txData *commondatabase.GrpcTxData) {
	if txData == nil {
		commonlog.Logger.Error("processEvent",
			zap.String("txData type: ", fmt.Sprintf("%T", txData)),
		)
		return
	}

	commonlog.Logger.Info("processEvent",
		zap.String("hash : ", txData.Hash),
	)

	chainIdInt, err := strconv.ParseInt(txData.ChainId[2:], 16, 64)
	if err != nil {
		commonlog.Logger.Error("ParseInt",
			zap.String("ParseInt", "invalid contract data"),
		)
	}

    ... 

	if contract, ok := c.GetContractAt(chainId, txData.To); ok {

		switch contract.Name {
		case commonprotocol.ContractVault:
			c.processEventVault(txData, receipt)

		case commonprotocol.ContractMarket:
			c.processEventMarket(txData, receipt)
        ...
		default:
			commonlog.Logger.Warn("processEvent",
				zap.String("Event not set up yet", contract.Name),
			)
		}
	}
    ...
}

```
- Role : Crawler 서비스로부터 들어온 Market,Farm,Vault Controller 등의 이벤트를 아래와 같이 분기처리하고 

```
func (c *ContractHandler) HandleFarmEventByName(log *types.Log, chainId, eventName string, contract *commonprotocol.Contract) {
	if contract == nil {
		commonlog.Logger.Warn("HandleMarketEventByName",
			zap.String("chainId", chainId),
			zap.String("eventName", eventName),
		)
		return
	}

	switch eventName {
	case "Stake":
		c.Stake(log, contract, chainId, eventName)

        ...
    }
}

```
아래와 같이 필요한 핸들러를 구현하여 메시지를 DB 저장에 의미있는 형태로 저장하고 변환하는 역할을 수행했다. 

```
func (c *ContractHandler) Stake(log *types.Log, contract *commonprotocol.Contract, chainId, eventName string) {

	event := farm.EventStake{}
	timestamp, date, err := c.ParseEvent(contract, log, chainId, eventName, &event)
	if err != nil {
		commonlog.Logger.Error(eventName,
			zap.String("UnmarshalEvent", err.Error()),
		)
		return
	}
    ... 

	amount, err := commonutils.Decimal128FromBigInt(event.Amount)
	if err != nil {
		commonlog.Logger.Error(eventName,
			zap.String("ConvertDecimalToBigInt", err.Error()),
		)
	}

	share, err := commonutils.Decimal128FromBigInt(new(big.Int).Div(new(big.Int).Mul(event.Amount, big.NewInt(100)), staking))
	if err != nil {
		commonlog.Logger.Error(eventName,
			zap.String("ConvertDecimalToBigInt", err.Error()),
		)
	}
    ...
}
```

그리고 Scheduler 에서는 Coinmarketcap API 호출을 통해 스테이블 코인 가격을 받아와서 특정 토큰 페어(ex. BTC/USDT) TVL 구하는 작업과 아래와 같이 최신 시장가를 계산해서 API 서비스에 주기적으로 전송하는 
태스크를 만드는 업무를 담당했다. 

```
func (b *BatchHandler) MethodMarketLast(ctx commoncontext.Context, title string, chainId *string) {
	...
	if err != nil {
		commonlog.Logger.Error(title,
			zap.String("GetMarkets", err.Error()),
		)
		return
	}

	now := time.Now().UTC().Unix()

	for _, m := range markets {
		...
		b.marketDB.GetLastAll(&now, last)
		b.SendMarketLast(chainId, &m.Address, last)
	}
}
```



[1]: https://github.com/allejo/jekyll-toc
